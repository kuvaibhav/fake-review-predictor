{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FineTuningBert-Tensorflow.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51qcGDiO6yMG",
        "outputId": "a6d126af-cfeb-44ce-f8f6-596232b75322"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgn0ouG06-8O"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IUWiw3S7BMS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "import pandas as pd\r\n",
        "import tensorflow_hub as hub\r\n",
        "from datetime import datetime"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuQ6PhS67Ep4",
        "outputId": "d2d60f79-e2e6-4309-ed50-4e869d0f8ff7"
      },
      "source": [
        "!pip install bert-tensorflow==1.0.1"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow==1.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |████▉                           | 10kB 14.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 11.6MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 8.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 8.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-tensorflow==1.0.1) (1.15.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3TAdtTH7Gwn",
        "outputId": "77a7101e-4e95-4c25-b8b6-432760d19c61"
      },
      "source": [
        "import bert\r\n",
        "from bert import run_classifier\r\n",
        "from bert import optimization\r\n",
        "from bert import tokenization"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_iIAz7E7cAb",
        "outputId": "66714ab2-6cf1-4bdf-d0c8-57d8134d3e9f"
      },
      "source": [
        "# Set the output directory for saving model file\r\n",
        "# Optionally, set a GCP bucket location\r\n",
        "\r\n",
        "OUTPUT_DIR = 'OUTPUT_DIR_KUMAR_VAIBHAV'#@param {type:\"string\"}\r\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\r\n",
        "DO_DELETE = True #@param {type:\"boolean\"}\r\n",
        "#@markdown Set USE_BUCKET and BUCKET if you want to (optionally) store model output on GCP bucket.\r\n",
        "USE_BUCKET = False #@param {type:\"boolean\"}\r\n",
        "BUCKET = 'BUCKET_NAME' #@param {type:\"string\"}\r\n",
        "\r\n",
        "if USE_BUCKET:\r\n",
        "  OUTPUT_DIR = 'gs://{}/{}'.format(BUCKET, OUTPUT_DIR)\r\n",
        "  from google.colab import auth\r\n",
        "  auth.authenticate_user()\r\n",
        "\r\n",
        "if DO_DELETE:\r\n",
        "  try:\r\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\r\n",
        "  except:\r\n",
        "    # Doesn't matter if the directory didn't exist\r\n",
        "    pass\r\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\r\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: OUTPUT_DIR_KUMAR_VAIBHAV *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJBThc0o7hes"
      },
      "source": [
        "train = pd.read_csv('/content/colab-min-data.csv', sep=\",\", encoding='Latin-1')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njVbvjHr7mI9"
      },
      "source": [
        "train.loc[train.label == 1, 'label'] = 0\r\n",
        "train.loc[train.label == -1, 'label'] = 1"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qT_SDF-7rii",
        "outputId": "ea83e8e9-efae-4324-d388-96a0e19380ba"
      },
      "source": [
        "train['date'] = pd.to_datetime(train['date'])\r\n",
        "train['day_of_week'] = train['date'].dt.day_name()\r\n",
        "train.day_of_week.value_counts()[:10]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sunday       2568\n",
              "Monday       2557\n",
              "Tuesday      2391\n",
              "Thursday     2287\n",
              "Friday       2231\n",
              "Wednesday    2205\n",
              "Saturday     2131\n",
              "Name: day_of_week, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GMAtULS78fB"
      },
      "source": [
        "dofw = train.day_of_week.unique()"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NSD2UxI7_GX",
        "outputId": "8cc1aad5-d1e8-4082-8796-3825162c8129"
      },
      "source": [
        "for day in range(len(dofw)):\r\n",
        "        label=train['label'][train.day_of_week == dofw[day]]\r\n",
        "        fake=len(label[label==1])\r\n",
        "        real=len(label[label==0])\r\n",
        "        \r\n",
        "        print(\"***********Day is \",dofw[day])\r\n",
        "        print(\"fake is \",fake)\r\n",
        "        print(\"real is \",real)\r\n",
        "        print(\"tot is \",fake+real)\r\n",
        "        print(\"Ratio is \",100*(fake/(fake+real)))\r\n",
        "        print(\"len is \",len(label))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***********Day is  Thursday\n",
            "fake is  1425\n",
            "real is  862\n",
            "tot is  2287\n",
            "Ratio is  62.30870135548754\n",
            "len is  2287\n",
            "***********Day is  Sunday\n",
            "fake is  1439\n",
            "real is  1129\n",
            "tot is  2568\n",
            "Ratio is  56.035825545171335\n",
            "len is  2568\n",
            "***********Day is  Wednesday\n",
            "fake is  1338\n",
            "real is  867\n",
            "tot is  2205\n",
            "Ratio is  60.68027210884354\n",
            "len is  2205\n",
            "***********Day is  Tuesday\n",
            "fake is  1441\n",
            "real is  950\n",
            "tot is  2391\n",
            "Ratio is  60.2676704307821\n",
            "len is  2391\n",
            "***********Day is  Saturday\n",
            "fake is  1234\n",
            "real is  897\n",
            "tot is  2131\n",
            "Ratio is  57.90708587517598\n",
            "len is  2131\n",
            "***********Day is  Monday\n",
            "fake is  1502\n",
            "real is  1055\n",
            "tot is  2557\n",
            "Ratio is  58.74071177160736\n",
            "len is  2557\n",
            "***********Day is  Friday\n",
            "fake is  1390\n",
            "real is  841\n",
            "tot is  2231\n",
            "Ratio is  62.30389959659346\n",
            "len is  2231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPRw7VGJ8AyN"
      },
      "source": [
        "import string\r\n",
        "train['char_count'] = train['review'].apply(len)\r\n",
        "train['word_count'] = train['review'].apply(lambda x: len(x.split()))\r\n",
        "train['word_density'] = train['char_count'] / (train['word_count']+1)\r\n",
        "train['punctuation_count'] = train['review'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation)))\r\n",
        "train['title_word_count'] = train['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\r\n",
        "train['upper_case_word_count'] = train['review'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia1xx3qS8PWl",
        "outputId": "6db146e7-53f4-43d8-82d2-cc3baf571b77"
      },
      "source": [
        "train['date'] = pd.to_datetime(train['date'])\r\n",
        "train['day_of_week'] = train['date'].dt.day_name()\r\n",
        "#train.day_of_week.value_counts()[:10]]\r\n",
        "dofw = train.day_of_week.unique()\r\n",
        "for day in range(len(dofw)):\r\n",
        "        label=train['label'][train.day_of_week == dofw[day]]\r\n",
        "        fake=len(label[label==1])\r\n",
        "        real=len(label[label==0])\r\n",
        "        \r\n",
        "        print(\"***********Day is \",dofw[day])\r\n",
        "        print(\"fake is \",fake)\r\n",
        "        print(\"real is \",real)\r\n",
        "        print(\"tot is \",fake+real)\r\n",
        "        print(\"len is \",len(label))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***********Day is  Thursday\n",
            "fake is  1425\n",
            "real is  862\n",
            "tot is  2287\n",
            "len is  2287\n",
            "***********Day is  Sunday\n",
            "fake is  1439\n",
            "real is  1129\n",
            "tot is  2568\n",
            "len is  2568\n",
            "***********Day is  Wednesday\n",
            "fake is  1338\n",
            "real is  867\n",
            "tot is  2205\n",
            "len is  2205\n",
            "***********Day is  Tuesday\n",
            "fake is  1441\n",
            "real is  950\n",
            "tot is  2391\n",
            "len is  2391\n",
            "***********Day is  Saturday\n",
            "fake is  1234\n",
            "real is  897\n",
            "tot is  2131\n",
            "len is  2131\n",
            "***********Day is  Monday\n",
            "fake is  1502\n",
            "real is  1055\n",
            "tot is  2557\n",
            "len is  2557\n",
            "***********Day is  Friday\n",
            "fake is  1390\n",
            "real is  841\n",
            "tot is  2231\n",
            "len is  2231\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx_TCgVP8Sa0"
      },
      "source": [
        "train['user_id_no_of_review'] = train.groupby('user_id')['user_id'].transform('size')\r\n",
        "train['user_id_ave_rating'] = train.groupby('user_id')['rating'].transform('mean')\r\n",
        "train['user_id_ave_no_words'] = train.groupby('user_id')['word_count'].transform('mean')\r\n",
        "train['user_id_max_review_a_day'] = train['user_id_no_of_review']\r\n",
        "grouped = train.groupby('user_id')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpFOiK5d8ov3"
      },
      "source": [
        "for name,group in grouped:\r\n",
        "    #print(name)\r\n",
        "    #print(group)\r\n",
        "    df2 = group.groupby('date').size().max()\r\n",
        "    #print(df2)\r\n",
        "    train.loc[train.user_id == name,'user_id_max_review_a_day'] = df2"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HjC8YQ5f8r5Z"
      },
      "source": [
        "train['prod_id_no_of_review'] = train.groupby('prod_id')['prod_id'].transform('size') + 1000.\r\n",
        "train['prod_id_ave_rating'] = train.groupby('prod_id')['rating'].transform('mean') + 1000.\r\n",
        "#train['prod_id_std_rating'] = train.groupby('prod_id')['rating'].transform('std') + 1000.\r\n",
        "train['prod_id_ave_no_words'] = train.groupby('prod_id')['word_count'].transform('mean') + 1000.\r\n",
        "train['prod_id_max_review_a_day'] = train['prod_id_no_of_review'] + 1000.\r\n",
        "grouped = train.groupby('prod_id')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVmTI2Ai83yV"
      },
      "source": [
        "train['total']=train.user_id.astype(str) + ' '+ train.prod_id.astype(str) + ' ' + train.rating.astype(str) + ' '+ \\\r\n",
        "train.user_id_no_of_review.astype(str) + ' ' + train.user_id_ave_rating.astype(str) + ' '+\\\r\n",
        "train.user_id_ave_no_words.astype(str) + ' ' + train.user_id_max_review_a_day.astype(str) + ' '+\\\r\n",
        "train.prod_id_no_of_review.astype(str) + ' ' + train.prod_id_ave_rating.astype(str) + ' '+\\\r\n",
        "train.prod_id_ave_no_words.astype(str) + ' ' + train.prod_id_max_review_a_day.astype(str) + ' '+\\\r\n",
        "train.day_of_week.astype(str) + ' '+train.review  "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CCxon_f85r4",
        "outputId": "cb35eb37-53c0-40ec-ef50-e7b400526ce9"
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['user_id', 'prod_id', 'rating', 'label', 'date', 'review', 'char_count',\n",
              "       'word_count', 'upper_case_word_count', 'word_density',\n",
              "       'punctuation_count', 'user_id_no_of_review', 'user_id_ave_rating',\n",
              "       'user_id_ave_no_words', 'user_id_max_review_a_day',\n",
              "       'prod_id_no_of_review', 'prod_id_ave_rating', 'prod_id_ave_no_words',\n",
              "       'prod_id_max_review_a_day', 'total', 'day_of_week', 'title_word_count'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0WNd0G589iB"
      },
      "source": [
        "from sklearn.utils import shuffle\r\n",
        "train = shuffle(train, random_state=0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eKJj64eF9Avh"
      },
      "source": [
        "test = train[7001:12000]\r\n",
        "valid = train[12001:]\r\n",
        "train = train[:7000]"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evtKOAVz9HgW"
      },
      "source": [
        "DATA_COLUMN = 'review'\r\n",
        "LABEL_COLUMN = 'label'\r\n",
        "# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\r\n",
        "label_list = [0, 1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YV5wMwjO9JqK"
      },
      "source": [
        "# Use the InputExample class from BERT's run_classifier code to create examples from the data\r\n",
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\r\n",
        "                                                                   text_a = x[DATA_COLUMN], \r\n",
        "                                                                   text_b = None, \r\n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\r\n",
        "valid_InputExamples = valid.apply(lambda x: bert.run_classifier.InputExample(guid=None, \r\n",
        "                                                                   text_a = x[DATA_COLUMN], \r\n",
        "                                                                   text_b = None, \r\n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\r\n",
        "\r\n",
        "test_InputExamples = test.apply(lambda x: bert.run_classifier.InputExample(guid=None, \r\n",
        "                                                                   text_a = x[DATA_COLUMN], \r\n",
        "                                                                   text_b = None, \r\n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RazCVxD19PXB",
        "outputId": "50086d52-f909-4612-bb5a-59b8f6950d75"
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\r\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\r\n",
        "\r\n",
        "def create_tokenizer_from_hub_module():\r\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\r\n",
        "  with tf.Graph().as_default():\r\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\r\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\r\n",
        "    with tf.Session() as sess:\r\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\r\n",
        "                                            tokenization_info[\"do_lower_case\"]])\r\n",
        "      \r\n",
        "  return bert.tokenization.FullTokenizer(\r\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\r\n",
        "\r\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6RtpQwG9S11",
        "outputId": "edad855d-00cd-4f1c-d327-0d51b24aab72"
      },
      "source": [
        "MAX_SEQ_LENGTH = 128\r\n",
        "# Convert our train and test features to InputFeatures that BERT understands.\r\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 7000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 7000\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] dear owner of soc ##o restaurant , please consider expanding to dc . i promise we ' ll welcome you with open arms ! the food was great , vibe is cool , and i swear the hi ##bis ##cus tea must have crack in it because i ordered 6 of them . i went for sunday br ##un ##ch while visiting ny and fell in love . i had the red velvet chicken and wa ##ffle plate , the sweet wings , and hi ##bis ##cus tea . . make reservations because it gets busy ! ! [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] dear owner of soc ##o restaurant , please consider expanding to dc . i promise we ' ll welcome you with open arms ! the food was great , vibe is cool , and i swear the hi ##bis ##cus tea must have crack in it because i ordered 6 of them . i went for sunday br ##un ##ch while visiting ny and fell in love . i had the red velvet chicken and wa ##ffle plate , the sweet wings , and hi ##bis ##cus tea . . make reservations because it gets busy ! ! [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 6203 3954 1997 27084 2080 4825 1010 3531 5136 9186 2000 5887 1012 1045 4872 2057 1005 2222 6160 2017 2007 2330 2608 999 1996 2833 2001 2307 1010 21209 2003 4658 1010 1998 1045 8415 1996 7632 18477 7874 5572 2442 2031 8579 1999 2009 2138 1045 3641 1020 1997 2068 1012 1045 2253 2005 4465 7987 4609 2818 2096 5873 6396 1998 3062 1999 2293 1012 1045 2018 1996 2417 10966 7975 1998 11333 18142 5127 1010 1996 4086 4777 1010 1998 7632 18477 7874 5572 1012 1012 2191 17829 2138 2009 4152 5697 999 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 6203 3954 1997 27084 2080 4825 1010 3531 5136 9186 2000 5887 1012 1045 4872 2057 1005 2222 6160 2017 2007 2330 2608 999 1996 2833 2001 2307 1010 21209 2003 4658 1010 1998 1045 8415 1996 7632 18477 7874 5572 2442 2031 8579 1999 2009 2138 1045 3641 1020 1997 2068 1012 1045 2253 2005 4465 7987 4609 2818 2096 5873 6396 1998 3062 1999 2293 1012 1045 2018 1996 2417 10966 7975 1998 11333 18142 5127 1010 1996 4086 4777 1010 1998 7632 18477 7874 5572 1012 1012 2191 17829 2138 2009 4152 5697 999 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i wandered in here for late breakfast on a saturday because i was in soho and hadn ' t eaten yet . i had the buck ##w ##hea ##t cr ##ep ##es with scrambled eggs , ham and gr ##uy ##ere . it was good and definitely hit the spot - but next time i would probably try something else . i hear the sunday br ##un ##ch is better and my friend rave ##s about their french onion soup so i need to return to try that . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i wandered in here for late breakfast on a saturday because i was in soho and hadn ' t eaten yet . i had the buck ##w ##hea ##t cr ##ep ##es with scrambled eggs , ham and gr ##uy ##ere . it was good and definitely hit the spot - but next time i would probably try something else . i hear the sunday br ##un ##ch is better and my friend rave ##s about their french onion soup so i need to return to try that . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 13289 1999 2182 2005 2397 6350 2006 1037 5095 2138 1045 2001 1999 23771 1998 2910 1005 1056 8828 2664 1012 1045 2018 1996 10131 2860 20192 2102 13675 13699 2229 2007 13501 6763 1010 10654 1998 24665 26230 7869 1012 2009 2001 2204 1998 5791 2718 1996 3962 1011 2021 2279 2051 1045 2052 2763 3046 2242 2842 1012 1045 2963 1996 4465 7987 4609 2818 2003 2488 1998 2026 2767 23289 2015 2055 2037 2413 20949 11350 2061 1045 2342 2000 2709 2000 3046 2008 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 13289 1999 2182 2005 2397 6350 2006 1037 5095 2138 1045 2001 1999 23771 1998 2910 1005 1056 8828 2664 1012 1045 2018 1996 10131 2860 20192 2102 13675 13699 2229 2007 13501 6763 1010 10654 1998 24665 26230 7869 1012 2009 2001 2204 1998 5791 2718 1996 3962 1011 2021 2279 2051 1045 2052 2763 3046 2242 2842 1012 1045 2963 1996 4465 7987 4609 2818 2003 2488 1998 2026 2767 23289 2015 2055 2037 2413 20949 11350 2061 1045 2342 2000 2709 2000 3046 2008 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] rude service . cr ##ammed tables . med ##io ##cre food . no substitution ##s on the menu - - not even easy ones . furniture and table ##ware in bad condition . dirty bathroom - - yu ##ck ! not going back . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] rude service . cr ##ammed tables . med ##io ##cre food . no substitution ##s on the menu - - not even easy ones . furniture and table ##ware in bad condition . dirty bathroom - - yu ##ck ! not going back . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 12726 2326 1012 13675 27479 7251 1012 19960 3695 16748 2833 1012 2053 20885 2015 2006 1996 12183 1011 1011 2025 2130 3733 3924 1012 7390 1998 2795 8059 1999 2919 4650 1012 6530 5723 1011 1011 9805 3600 999 2025 2183 2067 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 12726 2326 1012 13675 27479 7251 1012 19960 3695 16748 2833 1012 2053 20885 2015 2006 1996 12183 1011 1011 2025 2130 3733 3924 1012 7390 1998 2795 8059 1999 2919 4650 1012 6530 5723 1011 1011 9805 3600 999 2025 2183 2067 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] does all the simple things right . good vibe . reasonable prices . at ##ten ##tive staff . good music . i ' m too young to be a regular here but this is a quality joint . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] does all the simple things right . good vibe . reasonable prices . at ##ten ##tive staff . good music . i ' m too young to be a regular here but this is a quality joint . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2515 2035 1996 3722 2477 2157 1012 2204 21209 1012 9608 7597 1012 2012 6528 6024 3095 1012 2204 2189 1012 1045 1005 1049 2205 2402 2000 2022 1037 3180 2182 2021 2023 2003 1037 3737 4101 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2515 2035 1996 3722 2477 2157 1012 2204 21209 1012 9608 7597 1012 2012 6528 6024 3095 1012 2204 2189 1012 1045 1005 1049 2205 2402 2000 2022 1037 3180 2182 2021 2023 2003 1037 3737 4101 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i like the concept . the meat ##balls are good . i had the chicken meat ##balls with pest ##o sauce and a side of mas ##hed potatoes . it was on top of a delicious ar ##ug ##ula salad with vegetables . i also had an ice cream sand ##w ##hic ##h . the prices are fair . you can go in there and fill yourself up with really good food for under 15 bucks . if anyone is in the area . . you should def ##f stop by and give it a try ! [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i like the concept . the meat ##balls are good . i had the chicken meat ##balls with pest ##o sauce and a side of mas ##hed potatoes . it was on top of a delicious ar ##ug ##ula salad with vegetables . i also had an ice cream sand ##w ##hic ##h . the prices are fair . you can go in there and fill yourself up with really good food for under 15 bucks . if anyone is in the area . . you should def ##f stop by and give it a try ! [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2066 1996 4145 1012 1996 6240 18510 2024 2204 1012 1045 2018 1996 7975 6240 18510 2007 20739 2080 12901 1998 1037 2217 1997 16137 9072 14629 1012 2009 2001 2006 2327 1997 1037 12090 12098 15916 7068 16521 2007 11546 1012 1045 2036 2018 2019 3256 6949 5472 2860 16066 2232 1012 1996 7597 2024 4189 1012 2017 2064 2175 1999 2045 1998 6039 4426 2039 2007 2428 2204 2833 2005 2104 2321 14189 1012 2065 3087 2003 1999 1996 2181 1012 1012 2017 2323 13366 2546 2644 2011 1998 2507 2009 1037 3046 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2066 1996 4145 1012 1996 6240 18510 2024 2204 1012 1045 2018 1996 7975 6240 18510 2007 20739 2080 12901 1998 1037 2217 1997 16137 9072 14629 1012 2009 2001 2006 2327 1997 1037 12090 12098 15916 7068 16521 2007 11546 1012 1045 2036 2018 2019 3256 6949 5472 2860 16066 2232 1012 1996 7597 2024 4189 1012 2017 2064 2175 1999 2045 1998 6039 4426 2039 2007 2428 2204 2833 2005 2104 2321 14189 1012 2065 3087 2003 1999 1996 2181 1012 1012 2017 2323 13366 2546 2644 2011 1998 2507 2009 1037 3046 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkI-rvyx9Zh5",
        "outputId": "db473ed8-ae6d-45cc-a4f1-4e858840cf19"
      },
      "source": [
        "valid_features = bert.run_classifier.convert_examples_to_features(valid_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 4369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 4369\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] we went here for our first year anniversary together . the first and only time i ' ve had french food was 13 years ago , while i was in france . this was the first time outside of a cr ##ois ##sant or two that i was eating french food in nyc . we ordered the roasted bee ##t salad and soft shell crab as app ##eti ##zers . i enjoyed the bee ##t salad but thought that the crab tasted more italian than anything else . i ordered the roasted lamb and my boyfriend ordered the ve ##al . i enjoyed the lamb and the su ##cc ##ulent sauce . there was potato au gr ##atin and sides of pure ##ed carrot , ca [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] we went here for our first year anniversary together . the first and only time i ' ve had french food was 13 years ago , while i was in france . this was the first time outside of a cr ##ois ##sant or two that i was eating french food in nyc . we ordered the roasted bee ##t salad and soft shell crab as app ##eti ##zers . i enjoyed the bee ##t salad but thought that the crab tasted more italian than anything else . i ordered the roasted lamb and my boyfriend ordered the ve ##al . i enjoyed the lamb and the su ##cc ##ulent sauce . there was potato au gr ##atin and sides of pure ##ed carrot , ca [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2057 2253 2182 2005 2256 2034 2095 5315 2362 1012 1996 2034 1998 2069 2051 1045 1005 2310 2018 2413 2833 2001 2410 2086 3283 1010 2096 1045 2001 1999 2605 1012 2023 2001 1996 2034 2051 2648 1997 1037 13675 10054 22341 2030 2048 2008 1045 2001 5983 2413 2833 1999 16392 1012 2057 3641 1996 28115 10506 2102 16521 1998 3730 5806 18081 2004 10439 20624 16750 1012 1045 5632 1996 10506 2102 16521 2021 2245 2008 1996 18081 12595 2062 3059 2084 2505 2842 1012 1045 3641 1996 28115 12559 1998 2026 6898 3641 1996 2310 2389 1012 1045 5632 1996 12559 1998 1996 10514 9468 27581 12901 1012 2045 2001 14557 8740 24665 20363 1998 3903 1997 5760 2098 25659 1010 6187 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2057 2253 2182 2005 2256 2034 2095 5315 2362 1012 1996 2034 1998 2069 2051 1045 1005 2310 2018 2413 2833 2001 2410 2086 3283 1010 2096 1045 2001 1999 2605 1012 2023 2001 1996 2034 2051 2648 1997 1037 13675 10054 22341 2030 2048 2008 1045 2001 5983 2413 2833 1999 16392 1012 2057 3641 1996 28115 10506 2102 16521 1998 3730 5806 18081 2004 10439 20624 16750 1012 1045 5632 1996 10506 2102 16521 2021 2245 2008 1996 18081 12595 2062 3059 2084 2505 2842 1012 1045 3641 1996 28115 12559 1998 2026 6898 3641 1996 2310 2389 1012 1045 5632 1996 12559 1998 1996 10514 9468 27581 12901 1012 2045 2001 14557 8740 24665 20363 1998 3903 1997 5760 2098 25659 1010 6187 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] by far one of my favorite spots my first choice for date nice would like if they honor ur open table reservation even tho ur running late the lobster shrimp & grit ##s om ##g . . . . . . . . . . . . . . the red velvet wa ##ffle ##s with butter ##mi ##lk fried chicken - heaven - & the mac and cheese - yes ##ss ##ss ##ss ##s god jam ##bala ##ya hmm ##mm ##m mmm ##m if the had a loyalty program i ' ll be they # 1 i ' m in there at least twice a week [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] by far one of my favorite spots my first choice for date nice would like if they honor ur open table reservation even tho ur running late the lobster shrimp & grit ##s om ##g . . . . . . . . . . . . . . the red velvet wa ##ffle ##s with butter ##mi ##lk fried chicken - heaven - & the mac and cheese - yes ##ss ##ss ##ss ##s god jam ##bala ##ya hmm ##mm ##m mmm ##m if the had a loyalty program i ' ll be they # 1 i ' m in there at least twice a week [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2011 2521 2028 1997 2026 5440 7516 2026 2034 3601 2005 3058 3835 2052 2066 2065 2027 3932 24471 2330 2795 11079 2130 27793 24471 2770 2397 1996 27940 20130 1004 24842 2015 18168 2290 1012 1012 1012 1012 1012 1012 1012 1012 1012 1012 1012 1012 1012 1012 1996 2417 10966 11333 18142 2015 2007 12136 4328 13687 13017 7975 1011 6014 1011 1004 1996 6097 1998 8808 1011 2748 4757 4757 4757 2015 2643 9389 25060 3148 17012 7382 2213 25391 2213 2065 1996 2018 1037 9721 2565 1045 1005 2222 2022 2027 1001 1015 1045 1005 1049 1999 2045 2012 2560 3807 1037 2733 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2011 2521 2028 1997 2026 5440 7516 2026 2034 3601 2005 3058 3835 2052 2066 2065 2027 3932 24471 2330 2795 11079 2130 27793 24471 2770 2397 1996 27940 20130 1004 24842 2015 18168 2290 1012 1012 1012 1012 1012 1012 1012 1012 1012 1012 1012 1012 1012 1012 1996 2417 10966 11333 18142 2015 2007 12136 4328 13687 13017 7975 1011 6014 1011 1004 1996 6097 1998 8808 1011 2748 4757 4757 4757 2015 2643 9389 25060 3148 17012 7382 2213 25391 2213 2065 1996 2018 1037 9721 2565 1045 1005 2222 2022 2027 1001 1015 1045 1005 1049 1999 2045 2012 2560 3807 1037 2733 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] cafe ##cit ##o is a wonderful restaurant , great bar with excellent drinks , and a perfect place for me to un ##wind after a long day at work or to begin my night on the weekend . the food quality is excellent , the mo ##jit ##os to die for , and the management is incredibly friendly and professional . i love the steak sandwich with delicious plant ##ain chips made in house accompanied by a fresh garlic mo ##jit ##o sauce . the chu ##rra ##sco is also one of my favorites , and their weekend br ##un ##ch menu is incredible . a regular stop for me and one that is consistently delicious and pleasant to visit ! they even have a twitter [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] cafe ##cit ##o is a wonderful restaurant , great bar with excellent drinks , and a perfect place for me to un ##wind after a long day at work or to begin my night on the weekend . the food quality is excellent , the mo ##jit ##os to die for , and the management is incredibly friendly and professional . i love the steak sandwich with delicious plant ##ain chips made in house accompanied by a fresh garlic mo ##jit ##o sauce . the chu ##rra ##sco is also one of my favorites , and their weekend br ##un ##ch menu is incredible . a regular stop for me and one that is consistently delicious and pleasant to visit ! they even have a twitter [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 7668 26243 2080 2003 1037 6919 4825 1010 2307 3347 2007 6581 8974 1010 1998 1037 3819 2173 2005 2033 2000 4895 11101 2044 1037 2146 2154 2012 2147 2030 2000 4088 2026 2305 2006 1996 5353 1012 1996 2833 3737 2003 6581 1010 1996 9587 18902 2891 2000 3280 2005 1010 1998 1996 2968 2003 11757 5379 1998 2658 1012 1045 2293 1996 21475 11642 2007 12090 3269 8113 11772 2081 1999 2160 5642 2011 1037 4840 20548 9587 18902 2080 12901 1012 1996 14684 11335 9363 2003 2036 2028 1997 2026 20672 1010 1998 2037 5353 7987 4609 2818 12183 2003 9788 1012 1037 3180 2644 2005 2033 1998 2028 2008 2003 10862 12090 1998 8242 2000 3942 999 2027 2130 2031 1037 10474 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 7668 26243 2080 2003 1037 6919 4825 1010 2307 3347 2007 6581 8974 1010 1998 1037 3819 2173 2005 2033 2000 4895 11101 2044 1037 2146 2154 2012 2147 2030 2000 4088 2026 2305 2006 1996 5353 1012 1996 2833 3737 2003 6581 1010 1996 9587 18902 2891 2000 3280 2005 1010 1998 1996 2968 2003 11757 5379 1998 2658 1012 1045 2293 1996 21475 11642 2007 12090 3269 8113 11772 2081 1999 2160 5642 2011 1037 4840 20548 9587 18902 2080 12901 1012 1996 14684 11335 9363 2003 2036 2028 1997 2026 20672 1010 1998 2037 5353 7987 4609 2818 12183 2003 9788 1012 1037 3180 2644 2005 2033 1998 2028 2008 2003 10862 12090 1998 8242 2000 3942 999 2027 2130 2031 1037 10474 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i have one tradition when i visit new york - i go to soho and have lunch at balthazar . it started in the 90 ' s when the art scene was still happening , before the galleries closed their doors and migrated to chelsea . at the time it was considered the ultimate hot spot , with lots of celebrities and no way to get a reservation . i went once and was lucky enough to sit in the bar area with a martini and order lunch . ever since , i ' ve made a point of finding balthazar and having one care ##free lunch . i ' ve over tipped a sad bathroom attendant on mother ' s day . i ' ve [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i have one tradition when i visit new york - i go to soho and have lunch at balthazar . it started in the 90 ' s when the art scene was still happening , before the galleries closed their doors and migrated to chelsea . at the time it was considered the ultimate hot spot , with lots of celebrities and no way to get a reservation . i went once and was lucky enough to sit in the bar area with a martini and order lunch . ever since , i ' ve made a point of finding balthazar and having one care ##free lunch . i ' ve over tipped a sad bathroom attendant on mother ' s day . i ' ve [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2031 2028 4535 2043 1045 3942 2047 2259 1011 1045 2175 2000 23771 1998 2031 6265 2012 25021 1012 2009 2318 1999 1996 3938 1005 1055 2043 1996 2396 3496 2001 2145 6230 1010 2077 1996 11726 2701 2037 4303 1998 13447 2000 9295 1012 2012 1996 2051 2009 2001 2641 1996 7209 2980 3962 1010 2007 7167 1997 12330 1998 2053 2126 2000 2131 1037 11079 1012 1045 2253 2320 1998 2001 5341 2438 2000 4133 1999 1996 3347 2181 2007 1037 24480 1998 2344 6265 1012 2412 2144 1010 1045 1005 2310 2081 1037 2391 1997 4531 25021 1998 2383 2028 2729 23301 6265 1012 1045 1005 2310 2058 11182 1037 6517 5723 16742 2006 2388 1005 1055 2154 1012 1045 1005 2310 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2031 2028 4535 2043 1045 3942 2047 2259 1011 1045 2175 2000 23771 1998 2031 6265 2012 25021 1012 2009 2318 1999 1996 3938 1005 1055 2043 1996 2396 3496 2001 2145 6230 1010 2077 1996 11726 2701 2037 4303 1998 13447 2000 9295 1012 2012 1996 2051 2009 2001 2641 1996 7209 2980 3962 1010 2007 7167 1997 12330 1998 2053 2126 2000 2131 1037 11079 1012 1045 2253 2320 1998 2001 5341 2438 2000 4133 1999 1996 3347 2181 2007 1037 24480 1998 2344 6265 1012 2412 2144 1010 1045 1005 2310 2081 1037 2391 1997 4531 25021 1998 2383 2028 2729 23301 6265 1012 1045 1005 2310 2058 11182 1037 6517 5723 16742 2006 2388 1005 1055 2154 1012 1045 1005 2310 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this place was very ta ##sty ! the fish ta ##co and em ##pan ##ada ##s were delicious but the pork ta ##co was just so - so . i had the margarita - sang ##ria was sweet and strong . the service was fast and everyone was polite . will definitely come back for round 2 ! [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] this place was very ta ##sty ! the fish ta ##co and em ##pan ##ada ##s were delicious but the pork ta ##co was just so - so . i had the margarita - sang ##ria was sweet and strong . the service was fast and everyone was polite . will definitely come back for round 2 ! [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2173 2001 2200 11937 21756 999 1996 3869 11937 3597 1998 7861 9739 8447 2015 2020 12090 2021 1996 15960 11937 3597 2001 2074 2061 1011 2061 1012 1045 2018 1996 24570 1011 6369 4360 2001 4086 1998 2844 1012 1996 2326 2001 3435 1998 3071 2001 13205 1012 2097 5791 2272 2067 2005 2461 1016 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2023 2173 2001 2200 11937 21756 999 1996 3869 11937 3597 1998 7861 9739 8447 2015 2020 12090 2021 1996 15960 11937 3597 2001 2074 2061 1011 2061 1012 1045 2018 1996 24570 1011 6369 4360 2001 4086 1998 2844 1012 1996 2326 2001 3435 1998 3071 2001 13205 1012 2097 5791 2272 2067 2005 2461 1016 999 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxxvmiWQ9jFk",
        "outputId": "2a7ff096-af75-4779-e119-158edc4882a0"
      },
      "source": [
        "test_features = bert.run_classifier.convert_examples_to_features(test_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 4999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 4999\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] possibly one of the most expensive restaurants i ' ve been too , but completely worth it . completely packed on a tuesday night , the waitress was wonderful , and when we had a problem with our food not being prepared to our liking , they brought us a whole new meal and gave us dessert on the house . i got the duck shepard ##s pie , which was delicious , the dessert we got was the chocolate mo ##uss ##e and it was phenomena ##l . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] possibly one of the most expensive restaurants i ' ve been too , but completely worth it . completely packed on a tuesday night , the waitress was wonderful , and when we had a problem with our food not being prepared to our liking , they brought us a whole new meal and gave us dessert on the house . i got the duck shepard ##s pie , which was delicious , the dessert we got was the chocolate mo ##uss ##e and it was phenomena ##l . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4298 2028 1997 1996 2087 6450 7884 1045 1005 2310 2042 2205 1010 2021 3294 4276 2009 1012 3294 8966 2006 1037 9857 2305 1010 1996 13877 2001 6919 1010 1998 2043 2057 2018 1037 3291 2007 2256 2833 2025 2108 4810 2000 2256 16663 1010 2027 2716 2149 1037 2878 2047 7954 1998 2435 2149 18064 2006 1996 2160 1012 1045 2288 1996 9457 22189 2015 11345 1010 2029 2001 12090 1010 1996 18064 2057 2288 2001 1996 7967 9587 17854 2063 1998 2009 2001 13352 2140 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 4298 2028 1997 1996 2087 6450 7884 1045 1005 2310 2042 2205 1010 2021 3294 4276 2009 1012 3294 8966 2006 1037 9857 2305 1010 1996 13877 2001 6919 1010 1998 2043 2057 2018 1037 3291 2007 2256 2833 2025 2108 4810 2000 2256 16663 1010 2027 2716 2149 1037 2878 2047 7954 1998 2435 2149 18064 2006 1996 2160 1012 1045 2288 1996 9457 22189 2015 11345 1010 2029 2001 12090 1010 1996 18064 2057 2288 2001 1996 7967 9587 17854 2063 1998 2009 2001 13352 2140 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] very cozy little restaurant with more outdoor seating than indoors . the decor is very home ##y and displays photos and post ##cards i ' m assuming the owners received from their customers . this place is cash only , but they do have an atm next to the bathroom . for dinner , pat ##es et traditions offers various cr ##ep ##es , salad ##s , and pasta ##s . definitely go for the cr ##ep ##es as , in my opinion , they do much better than the other offerings . coming with a group of friends , i was able to try a cr ##ep ##e and sample two kinds of pasta . la pope ##ye - this is the buck ##w ##hea [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] very cozy little restaurant with more outdoor seating than indoors . the decor is very home ##y and displays photos and post ##cards i ' m assuming the owners received from their customers . this place is cash only , but they do have an atm next to the bathroom . for dinner , pat ##es et traditions offers various cr ##ep ##es , salad ##s , and pasta ##s . definitely go for the cr ##ep ##es as , in my opinion , they do much better than the other offerings . coming with a group of friends , i was able to try a cr ##ep ##e and sample two kinds of pasta . la pope ##ye - this is the buck ##w ##hea [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2200 26931 2210 4825 2007 2062 7254 10747 2084 24274 1012 1996 25545 2003 2200 2188 2100 1998 8834 7760 1998 2695 17965 1045 1005 1049 10262 1996 5608 2363 2013 2037 6304 1012 2023 2173 2003 5356 2069 1010 2021 2027 2079 2031 2019 27218 2279 2000 1996 5723 1012 2005 4596 1010 6986 2229 3802 7443 4107 2536 13675 13699 2229 1010 16521 2015 1010 1998 24857 2015 1012 5791 2175 2005 1996 13675 13699 2229 2004 1010 1999 2026 5448 1010 2027 2079 2172 2488 2084 1996 2060 14927 1012 2746 2007 1037 2177 1997 2814 1010 1045 2001 2583 2000 3046 1037 13675 13699 2063 1998 7099 2048 7957 1997 24857 1012 2474 4831 6672 1011 2023 2003 1996 10131 2860 20192 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2200 26931 2210 4825 2007 2062 7254 10747 2084 24274 1012 1996 25545 2003 2200 2188 2100 1998 8834 7760 1998 2695 17965 1045 1005 1049 10262 1996 5608 2363 2013 2037 6304 1012 2023 2173 2003 5356 2069 1010 2021 2027 2079 2031 2019 27218 2279 2000 1996 5723 1012 2005 4596 1010 6986 2229 3802 7443 4107 2536 13675 13699 2229 1010 16521 2015 1010 1998 24857 2015 1012 5791 2175 2005 1996 13675 13699 2229 2004 1010 1999 2026 5448 1010 2027 2079 2172 2488 2084 1996 2060 14927 1012 2746 2007 1037 2177 1997 2814 1010 1045 2001 2583 2000 3046 1037 13675 13699 2063 1998 7099 2048 7957 1997 24857 1012 2474 4831 6672 1011 2023 2003 1996 10131 2860 20192 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i went to miriam ' s expecting a nice time and maybe some food . my friend and i were in the area and decided we wanted to get a drink to cool down . then , we felt the racism of the staff . we were told that there was no space at the bar ( there were 3 stool ##s open ) and that we couldn ' t sit down because of their reservations ( it was 5 ##pm and only about 4 people sitting and eating ) . it was then that we realized it was because we were people of color . my is friend is black and i ' m hispanic . people of color , boycott this place . you [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i went to miriam ' s expecting a nice time and maybe some food . my friend and i were in the area and decided we wanted to get a drink to cool down . then , we felt the racism of the staff . we were told that there was no space at the bar ( there were 3 stool ##s open ) and that we couldn ' t sit down because of their reservations ( it was 5 ##pm and only about 4 people sitting and eating ) . it was then that we realized it was because we were people of color . my is friend is black and i ' m hispanic . people of color , boycott this place . you [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2253 2000 16925 1005 1055 8074 1037 3835 2051 1998 2672 2070 2833 1012 2026 2767 1998 1045 2020 1999 1996 2181 1998 2787 2057 2359 2000 2131 1037 4392 2000 4658 2091 1012 2059 1010 2057 2371 1996 14398 1997 1996 3095 1012 2057 2020 2409 2008 2045 2001 2053 2686 2012 1996 3347 1006 2045 2020 1017 14708 2015 2330 1007 1998 2008 2057 2481 1005 1056 4133 2091 2138 1997 2037 17829 1006 2009 2001 1019 9737 1998 2069 2055 1018 2111 3564 1998 5983 1007 1012 2009 2001 2059 2008 2057 3651 2009 2001 2138 2057 2020 2111 1997 3609 1012 2026 2003 2767 2003 2304 1998 1045 1005 1049 6696 1012 2111 1997 3609 1010 17757 2023 2173 1012 2017 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2253 2000 16925 1005 1055 8074 1037 3835 2051 1998 2672 2070 2833 1012 2026 2767 1998 1045 2020 1999 1996 2181 1998 2787 2057 2359 2000 2131 1037 4392 2000 4658 2091 1012 2059 1010 2057 2371 1996 14398 1997 1996 3095 1012 2057 2020 2409 2008 2045 2001 2053 2686 2012 1996 3347 1006 2045 2020 1017 14708 2015 2330 1007 1998 2008 2057 2481 1005 1056 4133 2091 2138 1997 2037 17829 1006 2009 2001 1019 9737 1998 2069 2055 1018 2111 3564 1998 5983 1007 1012 2009 2001 2059 2008 2057 3651 2009 2001 2138 2057 2020 2111 1997 3609 1012 2026 2003 2767 2003 2304 1998 1045 1005 1049 6696 1012 2111 1997 3609 1010 17757 2023 2173 1012 2017 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] it might be un ##wise to be a buzz - kill for a place as revered as luca ##li , but to be completely frank , the pizza did not live up to its billing , and certainly not its price . to be clear : the pizza here is excellent . but you ' ve had better , and if you haven ' t , you should keep looking . usually packed , i went most recently on a tuesday night and was met with a comfortably filled restaurant with tables to choose from . very nice . the decor is simple and relaxed and very welcoming . the lighting is appropriate and the mood lively , but not overwhelming . the menu is pizza [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] it might be un ##wise to be a buzz - kill for a place as revered as luca ##li , but to be completely frank , the pizza did not live up to its billing , and certainly not its price . to be clear : the pizza here is excellent . but you ' ve had better , and if you haven ' t , you should keep looking . usually packed , i went most recently on a tuesday night and was met with a comfortably filled restaurant with tables to choose from . very nice . the decor is simple and relaxed and very welcoming . the lighting is appropriate and the mood lively , but not overwhelming . the menu is pizza [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2009 2453 2022 4895 14244 2000 2022 1037 12610 1011 3102 2005 1037 2173 2004 23886 2004 15604 3669 1010 2021 2000 2022 3294 3581 1010 1996 10733 2106 2025 2444 2039 2000 2049 25640 1010 1998 5121 2025 2049 3976 1012 2000 2022 3154 1024 1996 10733 2182 2003 6581 1012 2021 2017 1005 2310 2018 2488 1010 1998 2065 2017 4033 1005 1056 1010 2017 2323 2562 2559 1012 2788 8966 1010 1045 2253 2087 3728 2006 1037 9857 2305 1998 2001 2777 2007 1037 18579 3561 4825 2007 7251 2000 5454 2013 1012 2200 3835 1012 1996 25545 2003 3722 1998 8363 1998 2200 18066 1012 1996 7497 2003 6413 1998 1996 6888 17133 1010 2021 2025 10827 1012 1996 12183 2003 10733 102\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2009 2453 2022 4895 14244 2000 2022 1037 12610 1011 3102 2005 1037 2173 2004 23886 2004 15604 3669 1010 2021 2000 2022 3294 3581 1010 1996 10733 2106 2025 2444 2039 2000 2049 25640 1010 1998 5121 2025 2049 3976 1012 2000 2022 3154 1024 1996 10733 2182 2003 6581 1012 2021 2017 1005 2310 2018 2488 1010 1998 2065 2017 4033 1005 1056 1010 2017 2323 2562 2559 1012 2788 8966 1010 1045 2253 2087 3728 2006 1037 9857 2305 1998 2001 2777 2007 1037 18579 3561 4825 2007 7251 2000 5454 2013 1012 2200 3835 1012 1996 25545 2003 3722 1998 8363 1998 2200 18066 1012 1996 7497 2003 6413 1998 1996 6888 17133 1010 2021 2025 10827 1012 1996 12183 2003 10733 102\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] it ' s my favorite place in korea town . they have cheap price with a variety of all the korean foods ! whenever i bring my friends , they love this place . it ' s also a best place to take out luc ##h box or to - go food for home . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] it ' s my favorite place in korea town . they have cheap price with a variety of all the korean foods ! whenever i bring my friends , they love this place . it ' s also a best place to take out luc ##h box or to - go food for home . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2009 1005 1055 2026 5440 2173 1999 4420 2237 1012 2027 2031 10036 3976 2007 1037 3528 1997 2035 1996 4759 9440 999 7188 1045 3288 2026 2814 1010 2027 2293 2023 2173 1012 2009 1005 1055 2036 1037 2190 2173 2000 2202 2041 12776 2232 3482 2030 2000 1011 2175 2833 2005 2188 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2009 1005 1055 2026 5440 2173 1999 4420 2237 1012 2027 2031 10036 3976 2007 1037 3528 1997 2035 1996 4759 9440 999 7188 1045 3288 2026 2814 1010 2027 2293 2023 2173 1012 2009 1005 1055 2036 1037 2190 2173 2000 2202 2041 12776 2232 3482 2030 2000 1011 2175 2833 2005 2188 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHmXfs99qtu"
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\r\n",
        "                 num_labels):\r\n",
        "  \"\"\"Creates a classification model.\"\"\"\r\n",
        "\r\n",
        "  bert_module = hub.Module(\r\n",
        "      BERT_MODEL_HUB,\r\n",
        "      trainable=True)\r\n",
        "  bert_inputs = dict(\r\n",
        "      input_ids=input_ids,\r\n",
        "      input_mask=input_mask,\r\n",
        "      segment_ids=segment_ids)\r\n",
        "  bert_outputs = bert_module(\r\n",
        "      inputs=bert_inputs,\r\n",
        "      signature=\"tokens\",\r\n",
        "      as_dict=True)\r\n",
        "\r\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\r\n",
        "  # Use \"sequence_outputs\" for token-level output.\r\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\r\n",
        "\r\n",
        "  hidden_size = output_layer.shape[-1].value\r\n",
        "\r\n",
        "  # Create our own layer to tune for politeness data.\r\n",
        "  output_weights = tf.get_variable(\r\n",
        "      \"output_weights\", [num_labels, hidden_size],\r\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\r\n",
        "\r\n",
        "  output_bias = tf.get_variable(\r\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\r\n",
        "\r\n",
        "  with tf.variable_scope(\"loss\"):\r\n",
        "\r\n",
        "    # Dropout helps prevent overfitting\r\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.7)\r\n",
        "\r\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\r\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\r\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\r\n",
        "\r\n",
        "    # Convert labels into one-hot encoding\r\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\r\n",
        "\r\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\r\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\r\n",
        "    if is_predicting:\r\n",
        "      return (predicted_labels, log_probs)\r\n",
        "\r\n",
        "    # If we're train/eval, compute loss between predicted and actual label\r\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\r\n",
        "    loss = tf.reduce_mean(per_example_loss)\r\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gotKKG8u9xD_"
      },
      "source": [
        "# model_fn_builder actually creates our model function\r\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\r\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\r\n",
        "                     num_warmup_steps):\r\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\r\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\r\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\r\n",
        "\r\n",
        "    input_ids = features[\"input_ids\"]\r\n",
        "    input_mask = features[\"input_mask\"]\r\n",
        "    segment_ids = features[\"segment_ids\"]\r\n",
        "    label_ids = features[\"label_ids\"]\r\n",
        "\r\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\r\n",
        "    \r\n",
        "    # TRAIN and EVAL\r\n",
        "    if not is_predicting:\r\n",
        "\r\n",
        "      (loss, predicted_labels, log_probs) = create_model(\r\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\r\n",
        "\r\n",
        "      train_op = bert.optimization.create_optimizer(\r\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\r\n",
        "\r\n",
        "      # Calculate evaluation metrics. \r\n",
        "      def metric_fn(label_ids, predicted_labels):\r\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\r\n",
        "        f1_score = tf.contrib.metrics.f1_score(\r\n",
        "            label_ids,\r\n",
        "            predicted_labels)\r\n",
        "        auc = tf.metrics.auc(\r\n",
        "            label_ids,\r\n",
        "            predicted_labels)\r\n",
        "        recall = tf.metrics.recall(\r\n",
        "            label_ids,\r\n",
        "            predicted_labels)\r\n",
        "        precision = tf.metrics.precision(\r\n",
        "            label_ids,\r\n",
        "            predicted_labels) \r\n",
        "        true_pos = tf.metrics.true_positives(\r\n",
        "            label_ids,\r\n",
        "            predicted_labels)\r\n",
        "        true_neg = tf.metrics.true_negatives(\r\n",
        "            label_ids,\r\n",
        "            predicted_labels)   \r\n",
        "        false_pos = tf.metrics.false_positives(\r\n",
        "            label_ids,\r\n",
        "            predicted_labels)  \r\n",
        "        false_neg = tf.metrics.false_negatives(\r\n",
        "            label_ids,\r\n",
        "            predicted_labels)\r\n",
        "        return {\r\n",
        "            \"eval_accuracy\": accuracy,\r\n",
        "            \"f1_score\": f1_score,\r\n",
        "            \"auc\": auc,\r\n",
        "            \"precision\": precision,\r\n",
        "            \"recall\": recall,\r\n",
        "            \"true_positives\": true_pos,\r\n",
        "            \"true_negatives\": true_neg,\r\n",
        "            \"false_positives\": false_pos,\r\n",
        "            \"false_negatives\": false_neg\r\n",
        "        }\r\n",
        "\r\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\r\n",
        "\r\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\r\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\r\n",
        "          loss=loss,\r\n",
        "          train_op=train_op)\r\n",
        "      else:\r\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\r\n",
        "            loss=loss,\r\n",
        "            eval_metric_ops=eval_metrics)\r\n",
        "    else:\r\n",
        "      (predicted_labels, log_probs) = create_model(\r\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\r\n",
        "\r\n",
        "      predictions = {\r\n",
        "          'probabilities': log_probs,\r\n",
        "          'labels': predicted_labels\r\n",
        "      }\r\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n",
        "\r\n",
        "  # Return the actual model function in the closure\r\n",
        "  return model_fn"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x07nWWcM9283"
      },
      "source": [
        "# Compute train and warmup steps from batch size\r\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\r\n",
        "BATCH_SIZE = 40\r\n",
        "LEARNING_RATE = 2e-5\r\n",
        "NUM_TRAIN_EPOCHS = 2.0\r\n",
        "# Warmup is a period of time where hte learning rate \r\n",
        "# is small and gradually increases--usually helps train.\r\n",
        "WARMUP_PROPORTION = 0.1\r\n",
        "# Model configs\r\n",
        "SAVE_CHECKPOINTS_STEPS = 500\r\n",
        "SAVE_SUMMARY_STEPS = 100"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfekgX9398QE"
      },
      "source": [
        "# Compute # train and warmup steps from batch size\r\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\r\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT50abLt-Cj6",
        "outputId": "7aed366d-35d3-460d-8d61-f0662d44f1d9"
      },
      "source": [
        "num_train_steps"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "350"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiAvj2Ek-EJs"
      },
      "source": [
        "# Specify outpit directory and number of checkpoint steps to save\r\n",
        "run_config = tf.estimator.RunConfig(\r\n",
        "    model_dir=OUTPUT_DIR,\r\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\r\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YhKnjMlq-UTs",
        "outputId": "ec2dd81b-3111-480f-8c54-df3fc2f65a06"
      },
      "source": [
        "model_fn = model_fn_builder(\r\n",
        "  num_labels=len(label_list),\r\n",
        "  learning_rate=LEARNING_RATE,\r\n",
        "  num_train_steps=num_train_steps,\r\n",
        "  num_warmup_steps=num_warmup_steps)\r\n",
        "\r\n",
        "estimator = tf.estimator.Estimator(\r\n",
        "  model_fn=model_fn,\r\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp66ms5gko\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp66ms5gko\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp66ms5gko', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f34d1c1eed0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp66ms5gko', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f34d1c1eed0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50W5s15P-W9H"
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\r\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\r\n",
        "    features=train_features,\r\n",
        "    seq_length=MAX_SEQ_LENGTH,\r\n",
        "    is_training=True,\r\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xN2SIub-aKz",
        "outputId": "773b4b16-2da0-4739-bf4d-99aa9dce615c"
      },
      "source": [
        "print(f'Beginning Training!')\r\n",
        "#current_time = datetime.now()\r\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\r\n",
        "print(\"Training took time \")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-de93265b2c41>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-26-de93265b2c41>:34: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/contrib/metrics/python/metrics/classification.py:162: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.743962, step = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.743962, step = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2 vs previous value: 2. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 2 vs previous value: 2. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4 vs previous value: 4. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 4 vs previous value: 4. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7 vs previous value: 7. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 7 vs previous value: 7. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 11 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 11 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10 vs previous value: 10. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 10 vs previous value: 10. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 16 vs previous value: 16. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 16 vs previous value: 16. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 22 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 22 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 33 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 33 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 45 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 45 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 57 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 57 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 69 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 69 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 81 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 81 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 92 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 92 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0182383\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0182383\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.48237476, step = 101 (5482.977 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.48237476, step = 101 (5482.977 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 103 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 103 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 114 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 114 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 126 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 126 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 137 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 137 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 148 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 148 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 159 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 159 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 170 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 170 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 181 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 181 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 192 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 192 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0182058\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0182058\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.32665616, step = 201 (5492.761 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.32665616, step = 201 (5492.761 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 203 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 203 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 214 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 214 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 225 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 225 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 236 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 236 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 247 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 247 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 258 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 258 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 269 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 269 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 280 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 280 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 291 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0181294\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:global_step/sec: 0.0181294\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.48388872, step = 301 (5515.914 sec)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.48388872, step = 301 (5515.914 sec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 302 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 302 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 313 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 313 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 324 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 324 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 335 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 335 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 346 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 346 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 350 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 350 into /tmp/tmp66ms5gko/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.237293.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.237293.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JcqvEut3dL-"
      },
      "source": [
        "valid_input_fn = run_classifier.input_fn_builder(\r\n",
        "    features=valid_features,\r\n",
        "    seq_length=MAX_SEQ_LENGTH,\r\n",
        "    is_training=False,\r\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mj3AO53aH2s6",
        "outputId": "fd0bb710-172f-4adc-cfb9-9c81701d8666"
      },
      "source": [
        "estimator.evaluate(input_fn=valid_input_fn, steps=None)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-03-09T03:55:15Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-03-09T03:55:15Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp66ms5gko/model.ckpt-350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp66ms5gko/model.ckpt-350\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-03-09-04:26:34\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-03-09-04:26:34\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 350: auc = 0.7770664, eval_accuracy = 0.7878233, f1_score = 0.8259154, false_negatives = 462.0, false_positives = 465.0, global_step = 350, loss = 0.4972468, precision = 0.8254505, recall = 0.8263811, true_negatives = 1243.0, true_positives = 2199.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 350: auc = 0.7770664, eval_accuracy = 0.7878233, f1_score = 0.8259154, false_negatives = 462.0, false_positives = 465.0, global_step = 350, loss = 0.4972468, precision = 0.8254505, recall = 0.8263811, true_negatives = 1243.0, true_positives = 2199.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 350: /tmp/tmp66ms5gko/model.ckpt-350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 350: /tmp/tmp66ms5gko/model.ckpt-350\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.7770664,\n",
              " 'eval_accuracy': 0.7878233,\n",
              " 'f1_score': 0.8259154,\n",
              " 'false_negatives': 462.0,\n",
              " 'false_positives': 465.0,\n",
              " 'global_step': 350,\n",
              " 'loss': 0.4972468,\n",
              " 'precision': 0.8254505,\n",
              " 'recall': 0.8263811,\n",
              " 'true_negatives': 1243.0,\n",
              " 'true_positives': 2199.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlzwNhXQH6yJ"
      },
      "source": [
        "test_input_fn = run_classifier.input_fn_builder(\r\n",
        "    features=test_features,\r\n",
        "    seq_length=MAX_SEQ_LENGTH,\r\n",
        "    is_training=False,\r\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ezqs1uzSQKuw",
        "outputId": "e662679c-dbef-4095-8b0b-0dc7935451ca"
      },
      "source": [
        "estimator.evaluate(input_fn=test_input_fn, steps=None)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/tensorflow-1.15.2/python3.7/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-03-09T04:31:55Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2021-03-09T04:31:55Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp66ms5gko/model.ckpt-350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp66ms5gko/model.ckpt-350\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-03-09-05:07:19\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2021-03-09-05:07:19\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 350: auc = 0.77135944, eval_accuracy = 0.77975595, f1_score = 0.8143651, false_negatives = 539.0, false_positives = 562.0, global_step = 350, loss = 0.5005893, precision = 0.81121933, recall = 0.8175355, true_negatives = 1483.0, true_positives = 2415.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 350: auc = 0.77135944, eval_accuracy = 0.77975595, f1_score = 0.8143651, false_negatives = 539.0, false_positives = 562.0, global_step = 350, loss = 0.5005893, precision = 0.81121933, recall = 0.8175355, true_negatives = 1483.0, true_positives = 2415.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 350: /tmp/tmp66ms5gko/model.ckpt-350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 350: /tmp/tmp66ms5gko/model.ckpt-350\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'auc': 0.77135944,\n",
              " 'eval_accuracy': 0.77975595,\n",
              " 'f1_score': 0.8143651,\n",
              " 'false_negatives': 539.0,\n",
              " 'false_positives': 562.0,\n",
              " 'global_step': 350,\n",
              " 'loss': 0.5005893,\n",
              " 'precision': 0.81121933,\n",
              " 'recall': 0.8175355,\n",
              " 'true_negatives': 1483.0,\n",
              " 'true_positives': 2415.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "sxu6IawpQULj",
        "outputId": "51057517-6054-45d5-d715-2f050050d04c"
      },
      "source": [
        "predictions = estimator.predict(test_input_fn)\r\n",
        "#list(predictions)[0]\r\n",
        "pred = pd.DataFrame(list(predictions))\r\n",
        "pred.head()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp66ms5gko/model.ckpt-350\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from /tmp/tmp66ms5gko/model.ckpt-350\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>probabilities</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.53277373, -0.88424635]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-1.1339865, -0.38823646]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.04270137, -3.1747983]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.06547266, -2.7586799]</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-4.162898, -0.015684811]</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                probabilities  labels\n",
              "0  [-0.53277373, -0.88424635]       0\n",
              "1   [-1.1339865, -0.38823646]       1\n",
              "2   [-0.04270137, -3.1747983]       0\n",
              "3   [-0.06547266, -2.7586799]       0\n",
              "4   [-4.162898, -0.015684811]       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "s41esndzYw0e",
        "outputId": "79fb2502-90cd-4bb8-fc6d-f894112c0c7a"
      },
      "source": [
        "import numpy as np\r\n",
        "pred[['log_p0', 'log_p1']] = pd.DataFrame(pred.probabilities.tolist()) \r\n",
        "pred['p1']= np.exp(pred['log_p1'])\r\n",
        "\r\n",
        "pred.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>probabilities</th>\n",
              "      <th>labels</th>\n",
              "      <th>log_p0</th>\n",
              "      <th>log_p1</th>\n",
              "      <th>p1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.53277373, -0.88424635]</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.532774</td>\n",
              "      <td>-0.884246</td>\n",
              "      <td>0.413025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-1.1339865, -0.38823646]</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.133986</td>\n",
              "      <td>-0.388236</td>\n",
              "      <td>0.678252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.04270137, -3.1747983]</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.042701</td>\n",
              "      <td>-3.174798</td>\n",
              "      <td>0.041803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.06547266, -2.7586799]</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.065473</td>\n",
              "      <td>-2.758680</td>\n",
              "      <td>0.063375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-4.162898, -0.015684811]</td>\n",
              "      <td>1</td>\n",
              "      <td>-4.162898</td>\n",
              "      <td>-0.015685</td>\n",
              "      <td>0.984438</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                probabilities  labels    log_p0    log_p1        p1\n",
              "0  [-0.53277373, -0.88424635]       0 -0.532774 -0.884246  0.413025\n",
              "1   [-1.1339865, -0.38823646]       1 -1.133986 -0.388236  0.678252\n",
              "2   [-0.04270137, -3.1747983]       0 -0.042701 -3.174798  0.041803\n",
              "3   [-0.06547266, -2.7586799]       0 -0.065473 -2.758680  0.063375\n",
              "4   [-4.162898, -0.015684811]       1 -4.162898 -0.015685  0.984438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2duuyTfzhCqz",
        "outputId": "22e6e3e2-d64a-44f1-e580-2a33a1d1f2c3"
      },
      "source": [
        "test = (test).reset_index()\r\n",
        "(test.label == pred.labels).value_counts()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     3903\n",
              "False    1096\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "CesTzDclhHb3",
        "outputId": "397886ff-b1f8-4c7d-b1d0-a478989fb22e"
      },
      "source": [
        "pred['true_labels'] = test.label\r\n",
        "pred['abs_dif'] = np.abs(pred.true_labels-pred.p1)\r\n",
        "pred['review'] = test['review']\r\n",
        "pred.head()"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>probabilities</th>\n",
              "      <th>labels</th>\n",
              "      <th>log_p0</th>\n",
              "      <th>log_p1</th>\n",
              "      <th>p1</th>\n",
              "      <th>true_labels</th>\n",
              "      <th>abs_dif</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-0.53277373, -0.88424635]</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.532774</td>\n",
              "      <td>-0.884246</td>\n",
              "      <td>0.413025</td>\n",
              "      <td>0</td>\n",
              "      <td>0.413025</td>\n",
              "      <td>Possibly one of the most expensive restaurants...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-1.1339865, -0.38823646]</td>\n",
              "      <td>1</td>\n",
              "      <td>-1.133986</td>\n",
              "      <td>-0.388236</td>\n",
              "      <td>0.678252</td>\n",
              "      <td>1</td>\n",
              "      <td>0.321748</td>\n",
              "      <td>Very cozy little restaurant with more outdoor ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-0.04270137, -3.1747983]</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.042701</td>\n",
              "      <td>-3.174798</td>\n",
              "      <td>0.041803</td>\n",
              "      <td>1</td>\n",
              "      <td>0.958197</td>\n",
              "      <td>I went to Miriam's expecting a nice time and m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-0.06547266, -2.7586799]</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.065473</td>\n",
              "      <td>-2.758680</td>\n",
              "      <td>0.063375</td>\n",
              "      <td>0</td>\n",
              "      <td>0.063375</td>\n",
              "      <td>It might be unwise to be a buzz-kill for a pla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-4.162898, -0.015684811]</td>\n",
              "      <td>1</td>\n",
              "      <td>-4.162898</td>\n",
              "      <td>-0.015685</td>\n",
              "      <td>0.984438</td>\n",
              "      <td>1</td>\n",
              "      <td>0.015562</td>\n",
              "      <td>It's my favorite place in Korea town. They hav...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                probabilities  ...                                             review\n",
              "0  [-0.53277373, -0.88424635]  ...  Possibly one of the most expensive restaurants...\n",
              "1   [-1.1339865, -0.38823646]  ...  Very cozy little restaurant with more outdoor ...\n",
              "2   [-0.04270137, -3.1747983]  ...  I went to Miriam's expecting a nice time and m...\n",
              "3   [-0.06547266, -2.7586799]  ...  It might be unwise to be a buzz-kill for a pla...\n",
              "4   [-4.162898, -0.015684811]  ...  It's my favorite place in Korea town. They hav...\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuhn28tthLM3"
      },
      "source": [
        "pred.to_csv(r'/content/no-feature-test-data-analysis.csv')"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sAcViT66hToK",
        "outputId": "8801d31b-fb60-4bb9-b443-ec969d102f8c"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "fpr, tpr, thresholds = metrics.roc_curve(pred.true_labels , pred.p1)\r\n",
        "auc = metrics.roc_auc_score(pred.true_labels , pred.p1)\r\n",
        "print(\"Auc ROC is \",auc)\r\n",
        "precision, recall, thresholds = metrics.precision_recall_curve(pred.true_labels , pred.p1)\r\n",
        "auc = metrics.auc(recall, precision)\r\n",
        "print(\"Auc PRC is \",auc)\r\n",
        "f1 = metrics.f1_score(pred.true_labels, pred.labels)\r\n",
        "print(\"F1 score is\",f1)\r\n",
        "print(\"Log loss is \",metrics.log_loss(pred.true_labels , pred.p1))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Auc ROC is  0.8574431420327665\n",
            "Auc PRC is  0.8870468002204435\n",
            "F1 score is 0.8147396889790399\n",
            "Log loss is  0.4990782460008157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "vCfjqwL3hi0L",
        "outputId": "2549b4f9-5cef-4580-c1cd-7f92c6b30661"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.plot(fpr, tpr, label='BERT-Only Reviews', color='r')\r\n",
        "plt.xlabel('False Positive Rate')\r\n",
        "plt.ylabel('True Positive Rate')\r\n",
        "plt.legend()\r\n",
        "plt.show()"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN3IjIs8hnr6"
      },
      "source": [
        "results = pd.DataFrame()\r\n",
        "results['prob'] = pred.p1\r\n",
        "results['predictions'] = pred.labels\r\n",
        "results['labels'] = pred.true_labels\r\n",
        "results.to_csv('/content/BERT-no-feature.csv') "
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "kpp21ayChtfo",
        "outputId": "53a7185c-7721-402a-a044-0b8d21b4b99e"
      },
      "source": [
        "pd.crosstab(results['labels'], results['predictions'])"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>predictions</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1493</td>\n",
              "      <td>552</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>544</td>\n",
              "      <td>2410</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "predictions     0     1\n",
              "labels                 \n",
              "0            1493   552\n",
              "1             544  2410"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYSWxAytifpN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}